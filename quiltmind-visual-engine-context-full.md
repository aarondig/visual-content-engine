# Quiltmind Visual Content Engine ‚Äì Full Project Context

**Generated from ChatGPT conversation**  
**Date:** 2025-04-22

---

## üìå Project Summary

The Quiltmind Visual Content Engine is a semi-automated tool designed to generate branded images for executive LinkedIn posts. The platform is being developed by Aaron Diggdon as part of a strategic design and AI workflow initiative at Quiltmind, a design strategy agency that helps executives build thought leadership online.

The system analyzes LinkedIn post content (typically 100‚Äì300 words), extracts tone and key message, cross-references client-specific brand identity data (colors, typography, logos), and generates a prompt for an AI image generator such as Replicate.ai. Users are then shown multiple generated visuals to select from, and the system logs selected visuals for future model refinement and brand consistency.

---

## üéØ Goals and Objectives

### Primary Goal (MVP)
Build a minimum viable product that:
- Accepts post content as input
- Analyzes tone and extracts message using OpenAI
- Maps this to a client‚Äôs brand identity (manual upload or scraped)
- Generates 3‚Äì5 visual options via Replicate
- Allows the user to select and store a visual, tagged with metadata

### Strategic Goals
- Enable scalable, consistent visual production across clients
- Reduce manual design workload while maintaining brand fidelity
- Create a foundational system that can evolve into a multi-user, multi-org AI content platform
- Train AI models per client to reflect brand tone and visual preferences
- Allow long-term platform-level prompt refinement based on admin feedback

---

## üèóÔ∏è Project Architecture Overview

### Tech Stack
- **Frontend**: Next.js (App Router) + TailwindCSS
- **Backend**: Node.js via Next.js API routes
- **Auth**: Supabase Auth (email-based for now)
- **Database**: Supabase (Postgres + Storage)
- **AI Services**:
  - OpenAI (GPT-4 Turbo) for tone/message extraction
  - Replicate.ai for image generation
- **Deployment**: Vercel (frontend/backend), Supabase for hosting DB + files

---

## üß† Project Roles & Perspectives

### Product Manager Perspective
- Problem: Manual design process slows down scalability
- Opportunity: Automate design without losing quality
- Success Metrics:
  - Visuals generated in under 1 minute
  - 90% brand adherence from generated content
  - 75%+ user selection rate of visuals
- Long-term: Unlock a client-scaleable, feedback-driven creative engine

### Tech Lead Perspective
- Priority: Modular, testable codebase
- Design backend logic for tone analysis, brand mapping, prompt generation, and visual selection as separate modules
- Use Supabase‚Äôs relational structure for org-client-post-image model
- Plan now for future billing, role access, and model training separation

---

## üîÑ Sprint Plan (Iterative Development)

### Sprint 0: Setup & Planning
- Initialize Next.js + Tailwind + Supabase connection
- Create project folders: `/lib`, `/components`, `/app/api`
- Set up `.env.local` with Supabase and API keys
- Create Supabase client module in `/lib/supabaseClient.ts`

### Sprint 1: Post-to-Visual Flow
- Input LinkedIn post
- Analyze tone/message (OpenAI)
- Choose brand style + visual preset
- Generate prompt and call Replicate
- Display images and store selected visual

### Sprint 2: Brand Upload & Scraping
- Upload logos, guides, colors
- If missing, scrape from client website (Cheerio/Puppeteer)
- Store brand guide as JSON (color, font, tone)

### Sprint 3: Feedback & Prompt Tuning
- Allow feedback on visuals (selected/not selected)
- Store prompt + feedback
- Prepare prompt refinement logic for future tuning

### Sprint 4: Org & Role Management
- Supabase Auth: Admin vs. User roles
- Row-Level Security (RLS) in Supabase
- Admins can add/edit users, manage clients, view platform-wide feedback

### Sprint 5: Client Visual Archive
- Post history per client
- View original post, tone, selected image, and timestamp
- Ability to download or regenerate visuals

### Sprint 6: (Optional) Style Preset System
- Create named style presets (e.g., Minimal, Geometric, Surreal)
- Store style definitions and inject them into prompt structure

---

## üóÉÔ∏è Supabase Schema

### Tables:
- `organizations`: id, name, created_at
- `users`: id, email, role, organization_id
- `clients`: id, name, organization_id, brand_guide, scrape_url
- `posts`: id, client_id, content, tone, core_message, tone_source, created_at
- `images`: id, post_id, prompt, image_url, style, selected, feedback_note, created_at

### Buckets:
- `brand-assets`: logo files, style guides, reference images
- `generated-images`: visual outputs generated by AI

---

## ‚öôÔ∏è AI Services Integration

### OpenAI (GPT-4 Turbo)
- Task: Extract tone and summarize key message
- API integration done via server route `/api/analyzePost`

### Replicate.ai
- Task: Generate images from prompt
- Prompt structure includes:
  - Post theme/message
  - Tone (optional or manual)
  - Style preset
  - Brand colors/fonts (if required)

---

## üîí User Roles & Permissions (Future Scope)

### Roles:
- **Admin**: Manage users, clients, brand guides, global settings, train base model
- **User**: Generate visuals, input posts, see client history
- **Organization**: Contains multiple users and clients

### Row-Level Access Controls:
- Users only see clients in their org
- Admins see all data within their org

---

## üîÑ Training Strategy & Feedback Loops

- Every image selection stores:
  - Prompt used
  - Style applied
  - Selected: true/false
  - Feedback (if provided)
- Over time, prompts per client can be tuned based on selected results
- Future: Admin can also train the base model independently of client-specific data

---

## üí≥ Billing (Future Scope)

- Usage-based billing via Stripe
- Metered charges based on:
  - Number of generations
  - Storage usage
  - AI model calls
- Organization-level subscription plans

---

## üìú Windsurf Setup Notes

- Windsurf Desktop is a local AI IDE (not just cloud)
- You can open your real repo and use ChatGPT-4.5 to code locally
- Context from this ChatGPT session is **not shared** with Windsurf
- To replicate this memory, create a `project_context.md` file
  - Include vision, stack, sprint plan, Supabase schema, etc.
- Paste that context into the Windsurf assistant on first launch

---

## üõ†Ô∏è Development Principles

- Prioritize modular code
- MVP should ship in under a week but be extendable
- All prompts should be editable and transparent
- Visual generation logic must be flexible for future models (e.g., SDXL, Midjourney)
- Logs and metadata must be structured for easy analysis

---

## ‚úÖ Final Thoughts

This document serves as the **starting blueprint** for building the Quiltmind Visual Content Engine. It reflects both short-term goals and long-term architectural thinking, intended for use by developers, designers, and AI systems supporting the build process.

For developers joining later: read this before touching anything.

